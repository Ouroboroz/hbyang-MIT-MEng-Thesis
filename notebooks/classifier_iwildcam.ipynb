{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2c8bd-e564-4281-b583-c6549147d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc2147-2862-4ed0-ac8d-5518f68ae394",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be6a7d-19da-4200-8878-92468a6fdd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepCORAL\n",
      "ERM\n",
      "groupDRO\n",
      "IRM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('ls /dccstor/hoo-misha-1/wilds/wilds/features/camelyon17/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40ed020-6114-4f12-a294-007f12477bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet121_id_val_features.npy\n",
      "densenet121_id_val_labels.npy\n",
      "densenet121_id_val_metadata.npy\n",
      "densenet121_test_features.npy\n",
      "densenet121_test_labels.npy\n",
      "densenet121_test_metadata.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_base = '/dccstor/hoo-misha-1/wilds/wilds/features/camelyon17/ERM'\n",
    "os.system('ls /dccstor/hoo-misha-1/wilds/wilds/features/camelyon17/ERM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa524084-821a-41a5-9d81-c1e237e4ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flm():\n",
    "    test_features = np.load(f'{path_base}/resnet50_test_features.npy')\n",
    "    test_labels = np.load(f'{path_base}/resnet50_test_labels.npy')\n",
    "    test_metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    return test_features, test_labels, test_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841da4c0-abd1-437a-8a57-0d9613fe7df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_cam_id(cutoff=50):\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    return unique_counts[0][unique_counts[1] > cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767a2a9-a753-4548-9c3a-b0d0cf766d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cam_ind(metadata, num_cams=1, cam_id = None):\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    if cam_id is None:\n",
    "        top_id = unique_counts[0][np.argpartition(unique_counts[1], -num_cams)[-num_cams:]]\n",
    "    else:\n",
    "        top_id = cam_id\n",
    "    print(f'Selecting cameras with ids {top_id}')\n",
    "    ind = np.zeros(metadata.shape[0]) == 1\n",
    "    for c_id in top_id:\n",
    "        ind = np.logical_or(ind,metadata[:,0] == c_id)\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2471854-55a3-4e65-ac93-daaa4a0220ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_flm(num_cams=1, cam_id = None):\n",
    "    features, labels, metadata = load_flm()\n",
    "    cam_ind = get_cam_ind(metadata, num_cams, cam_id)\n",
    "    return features[cam_ind], labels[cam_ind], metadata[cam_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3c85d-958a-4228-b298-71bf19ad1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_flm(features, labels, metadata, cutoff=25):\n",
    "    unique_counts = np.unique(labels,return_counts=True)\n",
    "    print(f'|   | Total number of classes {len(unique_counts[0])}')\n",
    "    prune_classes = unique_counts[0][unique_counts[1] < cutoff]\n",
    "    prune_ind = []\n",
    "    for clss in prune_classes:\n",
    "        prune_ind.append((labels == clss).nonzero()[0])\n",
    "    print(f'|   |   | Pruning {len(prune_classes)} classes with {len(np.concatenate(prune_ind))} data points')\n",
    "    if len(prune_ind) == 0:\n",
    "        return features, labels, metadata\n",
    "    prune_ind = np.concatenate(prune_ind)\n",
    "    pruned_ind = np.ones(labels.shape[0]) == 1\n",
    "    pruned_ind[prune_ind] = False\n",
    "    return features[pruned_ind], labels[pruned_ind], metadata[pruned_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15171f91-37ff-4e5d-84cf-6276a96532c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_sample_ind(labels, batch = 5):\n",
    "    unique_classes = np.unique(labels)\n",
    "    #print(unique_classes)\n",
    "    ret_ind = None\n",
    "    for clss in unique_classes:\n",
    "        class_ind = np.where(labels == clss)[0]\n",
    "        #print(clss, class_ind)\n",
    "        rand_ind = rng.choice(class_ind,batch)\n",
    "        if ret_ind is None:\n",
    "            ret_ind = rand_ind\n",
    "        else:\n",
    "            ret_ind = np.concatenate((ret_ind, rand_ind))\n",
    "    return ret_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c42404-6220-4820-9f3d-5fe0dac58112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_accuracy(num_cams=1, largest=True, cam_id = None, cutoff = 25, batch = 5):\n",
    "    f,l,m = cam_flm(num_cams, cam_id)\n",
    "    f,l,m = prune_flm(f,l,m, cutoff)\n",
    "    sampled_ind = balanced_sample_ind(l,batch)\n",
    "    nonsampled_ind = np.ones(l.shape[0]) == 1\n",
    "    nonsampled_ind[sampled_ind] = False\n",
    "    try:\n",
    "        clf = LogisticRegression(random_state=0,max_iter=2000).fit(f[sampled_ind], l[sampled_ind])\n",
    "        predictions = clf.predict(f[nonsampled_ind])\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "    return np.sum(predictions == l[nonsampled_ind])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1303aee7-c040-45d4-9dfb-38a44b649e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_accuracy(num_cams=1, largest=True, cam_id = None, cutoff = 25):\n",
    "    f,l,m = cam_flm(num_cams, cam_id)\n",
    "    f,l,m = prune_flm(f,l,m, cutoff)\n",
    "    weight = np.load('pseudo_classifier_weight.npy')\n",
    "    bias = np.load('pseudo_classifier_bias.npy')\n",
    "    pred_logits = f @ weight.T + bias\n",
    "    pred = np.argmax(pred_logits,axis=1)\n",
    "    return np.sum(pred == l)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c62cb1-5507-4c27-a62f-9eaab373079e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1 to check\n",
      "| Cam ID 2\n",
      "Selecting cameras with ids [2]\n",
      "|   | Total number of classes 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m| Cam ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcam_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m cam_dict[cam_id] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 10\u001b[0m orig_dict[cam_id] \u001b[38;5;241m=\u001b[39m \u001b[43mget_original_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcam_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcam_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|   | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morig_dict[cam_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,cutoff):\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mget_original_accuracy\u001b[0;34m(num_cams, largest, cam_id, cutoff, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_original_accuracy\u001b[39m(num_cams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, largest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cam_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet50\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m     f,l,m \u001b[38;5;241m=\u001b[39m cam_flm(num_cams, cam_id, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m----> 3\u001b[0m     f,l,m \u001b[38;5;241m=\u001b[39m \u001b[43mprune_flm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpseudo_classifier_weight.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     bias \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpseudo_classifier_bias.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mprune_flm\u001b[0;34m(features, labels, metadata, cutoff)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clss \u001b[38;5;129;01min\u001b[39;00m prune_classes:\n\u001b[1;32m      7\u001b[0m     prune_ind\u001b[38;5;241m.\u001b[39mappend((labels \u001b[38;5;241m==\u001b[39m clss)\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|   |   | Pruning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prune_classes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m classes with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39mconcatenate(prune_ind))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data points\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prune_ind) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features, labels, metadata\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "cam_ids = prune_cam_id()\n",
    "print(f'Total {len(cam_ids)} to check')\n",
    "cam_dict = {}\n",
    "orig_dict = {}\n",
    "cutoff = 25\n",
    "for cam_id in cam_ids:\n",
    "    print(f'| Cam ID {cam_id}')\n",
    "    cam_dict[cam_id] = []\n",
    "    orig_dict[cam_id] = get_original_accuracy(cam_id=[cam_id], cutoff=cutoff)\n",
    "    print(f'|   | {orig_dict[cam_id]}')\n",
    "    for batch in range(1,cutoff):\n",
    "        print(f'|   | {batch}')\n",
    "        prediction_acc = 0\n",
    "        for i in range(3):\n",
    "            prediction_acc += get_prediction_accuracy(cam_id = [cam_id], cutoff=cutoff, batch=batch)\n",
    "        prediction_acc /= 3\n",
    "        print(f'|   | {prediction_acc}')\n",
    "        cam_dict[cam_id].append(prediction_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39c1f5-f250-4d68-8b28-b23b258d9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_dict(model):\n",
    "    root_path = '/dccstor/hoo-misha-1/wilds/wilds/results/iwildcam'\n",
    "    base_path = f'{root_path}/{model}'\n",
    "    \n",
    "    with open(f'{base_path}_cam_dict.pkl','rb') as file:\n",
    "        cam_dict = pickle.load(file)\n",
    "\n",
    "    with open(f'{base_path}_orig_dict.pkl','rb') as file:\n",
    "        orig_dict = pickle.load(file)\n",
    "    \n",
    "    return cam_dict, orig_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "734dbc18-42dd-4b7a-a0b6-d51babc21a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_dict, orig_dict = get_dict('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eb72f18-34e4-40aa-9df4-c011023c35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_ids = prune_cam_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3631bf3-2704-43b5-86be-71e16a64685e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31a64480033482899dc2b198b073435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=17, description='cam_ind', max=35), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(cam_ind):\n",
    "    predictions = cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    plt.plot(range(0,len(predictions)), predictions)\n",
    "    \n",
    "interact(plot, cam_ind=(0,len(cam_ids)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61583041-060c-4d37-bba7-a9f3e26bcd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2c59c781bb4f9283072de27908d806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=11, description='cam_ind', max=22), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "good_inds = []\n",
    "for i in range(len(cam_ids)):\n",
    "    predictions = cam_dict[cam_ids[i]]\n",
    "    if predictions[-1] > 0:\n",
    "        good_inds.append(i)\n",
    "        \n",
    "def plot_2(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    print(f'Camera id {cam_ids[cam_ind]}')\n",
    "    predictions = cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    plt.plot(range(0,len(predictions)), predictions)\n",
    "\n",
    "\n",
    "interact(plot_2, cam_ind=(0,len(good_inds)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a60dc5b6-3ef8-42e3-996a-b1696cd70054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0005de7baca84d45be328d4d0dae7c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=17, description='cam_ind', max=34), IntSlider(value=25, description='cut…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_green(text, green=True, end='\\n'):\n",
    "    print(f'\\x1b[{32 if green else 31}m{text}\\x1b[0m', end=end)\n",
    "def show_dist(cam_ind, cutoff=25):\n",
    "    f,l,m = cam_flm(cam_id=[cam_ids[cam_ind]])\n",
    "    unique_counts = np.unique(l, return_counts=True)\n",
    "    print(f'Total of {sum(unique_counts[1] > cutoff)} classes over cutoff')\n",
    "    print('[',end='')\n",
    "    for y,c in zip(unique_counts[0], unique_counts[1]):\n",
    "        print_green(f'{y}:{c}:{c/sum(unique_counts[1]):.2f}, ', c > cutoff, end='')\n",
    "    print(']')\n",
    "\n",
    "interact(show_dist, cam_ind=(0,len(cam_ids)-1), cutoff=(10,500));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aea3aaeb-ecd6-43d4-a009-4ffc54608ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f704a5ed5c4707a76ac74b80d76edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='model_ind', max=5), IntSlider(value=10, description='cam…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_path = '/dccstor/hoo-misha-1/wilds/wilds/features/iwildcam'\n",
    "models = list(os.listdir(root_path))\n",
    "\n",
    "def plot_3(model_ind, cam_ind):\n",
    "    global cam_dict, orig_dict\n",
    "    model = models[model_ind]\n",
    "    print(f'Using {model}')\n",
    "    cam_dict, orig_dict = get_dict(model)\n",
    "    plot_2(cam_ind)\n",
    "\n",
    "interact(plot_3, model_ind=(0,len(models)-1), cam_ind=(0,len(good_inds)-1));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0acccb69-655a-4eff-8a22-c3ff8d759ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('cam_dict.pkl','wb') as file:\n",
    "#     pickle.dump(cam_dict, file)\n",
    "    \n",
    "# with open('orig_dict.pkl','wb') as file:\n",
    "#     pickle.dump(orig_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366d97a-7daa-4098-a16f-bf19ab4b48b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
