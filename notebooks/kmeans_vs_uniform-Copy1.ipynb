{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b0d069-8059-4437-ac6d-8bd8e9e63da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/dccstor/hoo-misha-1/wilds/WOODS')\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e2a5b30-29c5-4ad1-bc6f-1f511b667b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02980e6b-c0c9-4857-8a6f-5e6bf4041e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'breeds'\n",
    "if dataset == 'iwildcam':\n",
    "    model_name = 'resnet50'\n",
    "elif dataset == 'breeds':\n",
    "    model_name = 'resnet50'\n",
    "elif dataset == 'camelyon17':\n",
    "    model_name = 'densenet121'\n",
    "elif dataset == 'cifar100':\n",
    "    model_name = 'resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70f322f5-35d2-4ad9-8b55-877f0e5c17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = f'/dccstor/hoo-misha-1/wilds/wilds/features/{dataset}'\n",
    "set_path_base(path_base)\n",
    "set_model_name(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dd7811e-6d7f-4dab-b7fd-4c29b2d5f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_algorithms_dict = {'balanced':'balanced_sample_ind', 'full':'full_kmeans_sample_ind', 'class':'class_kmeans_sample_ind', 'iterative':'iterative_kmeans_sample_ind', 'weighted':'weighted_iterative_kmeans_sample_ind', 'typiclust':'typiclust_sampled_ind'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "123bdea2-fba2-476f-8604-22cea3d1ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_path(root_path):\n",
    "    cam_dict_path = f'{root_path}_cam_dict.pkl'\n",
    "    orig_dict_path = f'{root_path}_orig_dict.pkl'\n",
    "    \n",
    "    with open(cam_dict_path,'rb') as file:\n",
    "        cam_dict = pickle.load(file)\n",
    "\n",
    "    with open(orig_dict_path,'rb') as file:\n",
    "        orig_dict = pickle.load(file)\n",
    "    \n",
    "    return cam_dict, orig_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7e1b948-ad1b-4f5b-9004-601abf8fa621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breeds_deepCORAL.pth',\n",
       " '.ipynb_checkpoints',\n",
       " 'breeds_wassersteindeepCORAL.pth',\n",
       " 'breeds_DANN.pth',\n",
       " 'breeds_ERM.pth']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f'/dccstor/hoo-misha-1/wilds/wilds/pretrained/{dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91610e2a-fa9b-4184-bd9d-492604a7204e",
   "metadata": {},
   "source": [
    "## Balanced Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c158f092-a34c-4cae-af1e-5b783b7c4962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpo model for balanced\n",
      "No checkpo model for iterative_False_True\n",
      "No checkpo model for typiclust\n",
      "No checkpo model for full\n",
      "No checkpo model for class\n",
      "No checkpo model for iterative\n",
      "No checkpo model for weighted\n",
      "No checkpo model for dense\n",
      "No wassersteindeepCORAL model for iterative_False_True\n",
      "No DANN model for iterative_False_True\n",
      "No ERM model for balanced\n",
      "No ERM model for iterative_False_True\n",
      "No ERM model for typiclust\n",
      "No ERM model for full\n",
      "No ERM model for class\n",
      "No ERM model for iterative\n",
      "No ERM model for weighted\n",
      "No ERM model for dense\n"
     ]
    }
   ],
   "source": [
    "cam_dicts = {}\n",
    "orig_dicts = {}\n",
    "ba_cam_dicts = {}\n",
    "ba_orig_dicts = {}\n",
    "models = []\n",
    "sampling_algorithms = set()\n",
    "\n",
    "for model in os.listdir(f'/dccstor/hoo-misha-1/wilds/wilds/pretrained/{dataset}'):\n",
    "    if dataset == 'iwildcam':\n",
    "        model = model[9:-4]\n",
    "    elif dataset == 'breeds':\n",
    "        model = model[7:-4]\n",
    "    elif dataset == 'camelyon17':\n",
    "        model = model[11:-4]\n",
    "    elif dataset == 'cifar100':\n",
    "        model = model[9:-4]\n",
    "    models.append(model)\n",
    "    cam_dicts[model] = {}\n",
    "    orig_dicts[model] = {}\n",
    "    ba_cam_dicts[model] = {}\n",
    "    ba_orig_dicts[model] = {}\n",
    "    #sampling_algorithms_dict = {'balanced':'balanced', 'full':'full', 'class':'class', 'iterative_pc:False_typ:False_w:False_d:False_phi:euclidean_lambda:1_rng:0':'no pc', 'iterative_pc:True_typ:True_w:False_d:False_phi:euclidean_lambda:1_rng:0':'typiclust', 'iterative_pc:True_typ:False_w:False_d:False_phi:euclidean_lambda:1_rng:0':'iterative', 'iterative_pc:True_typ:False_w:True_d:False_phi:euclidean_lambda:1_rng:0':'weighted', 'iterative_pc:True_typ:False_w:True_d:True_phi:euclidean_lambda:1_rng:0':'dense'}\n",
    "    sampling_algorithms_dict = {'balanced':'balanced','iterative_False_True':'iterative_False_True','typiclust':'typiclust', 'full':'full', 'class':'class','iterative':'iterative', 'weighted':'weighted', 'dense':'dense'}\n",
    "    for sampling_algorithm in sampling_algorithms_dict.keys():\n",
    "        try:\n",
    "            cam_dict, orig_dict = get_dict_path(f'/dccstor/hoo-misha-1/wilds/WOODS/results/{dataset}/{model}/{model}_{sampling_algorithm}')\n",
    "            cam_dicts[model][sampling_algorithms_dict[sampling_algorithm]] = cam_dict\n",
    "            orig_dicts[model][sampling_algorithms_dict[sampling_algorithm]] = orig_dict\n",
    "            ba_cam_dict, ba_orig_dict = get_dict_path(f'/dccstor/hoo-misha-1/wilds/WOODS/results/{dataset}/{model}/{model}_{sampling_algorithm}_ba')\n",
    "            ba_cam_dicts[model][sampling_algorithms_dict[sampling_algorithm]] = ba_cam_dict\n",
    "            ba_orig_dicts[model][sampling_algorithms_dict[sampling_algorithm]] = ba_orig_dict\n",
    "        except:\n",
    "            print(f'No {model} model for {sampling_algorithm}')\n",
    "            continue\n",
    "        sampling_algorithms.add(sampling_algorithms_dict[sampling_algorithm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e988de8-bc42-4925-90e8-9ac5bf6a6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.remove('IRM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d70cd50b-a0bf-4250-af3f-13acf78c1653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_green(text, green=True, end='\\n'):\n",
    "    print(f'\\x1b[{32 if green else 31}m{text}\\x1b[0m', end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da76e796-3fc6-4450-ad75-9c13e3f978e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['balanced', 'iterative_False_True', 'typiclust', 'full', 'class', 'iterative', 'weighted', 'dense'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_dicts[models[0]].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "43bd6ad3-f1ef-4d13-9603-4c00abe52825",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_domains = cam_dicts[models[0]]['balanced'].keys()\n",
    "# good_domains = None\n",
    "# all_domains = set()\n",
    "# for model, sampling_dict in cam_dicts.items():\n",
    "#     for sampling_algorithm, domain_dict in sampling_dict.items():\n",
    "#             if sampling_algorithm =='weighted':\n",
    "#                 continue\n",
    "#             good_domain_subset = set()\n",
    "#             print(model, sampling_algorithm, len(domain_dict.keys()))\n",
    "#             for domain, predictions in domain_dict.items():\n",
    "#                 all_domains.add(domain)\n",
    "#                 #if min(predictions) > 0:\n",
    "#                     #print(model, min(predictions), domain)\n",
    "#                 if len(predictions) != 0:\n",
    "#                     good_domain_subset.add(domain)\n",
    "#             if good_domains is None:\n",
    "#                 good_domains = good_domain_subset\n",
    "#             elif len(good_domain_subset) == 0:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 good_domains &= good_domain_subset\n",
    "            \n",
    "good_domains = sorted(list(good_domains))\n",
    "#all_domains = sorted(list(all_domains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c51d04d8-9854-43f6-a77b-3b74a69fbd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(good_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ecee9fc6-b6be-4ee5-9698-3811f44419fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ed481840ac427c8c2248d001004ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(SelectMultiple(description='Model:', index=(4,), options=('deepCORAL', 'checkpo'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_widget = widgets.SelectMultiple(\n",
    "    options=models,\n",
    "    value=['ERM'],\n",
    "    # rows=10,\n",
    "    description='Model:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "domain_widget = widgets.Dropdown(\n",
    "    options=good_domains,\n",
    "    value=good_domains[0],\n",
    "    description='Domains:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "sampling_algorithms = list(sampling_algorithms)\n",
    "sampling_algorithms.sort()\n",
    "sampling_widget = widgets.SelectMultiple(\n",
    "    options=sampling_algorithms, \n",
    "    #rows=10,\n",
    "    description='Sampling Algorithms',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def f(model_options,domain_option, sampling_option):\n",
    "    for model_option in model_options:\n",
    "        metadata = np.load(f'{path_base}/{model_option}/{model_name}_test_metadata.npy')\n",
    "        for sampling_algorithm in sampling_option:\n",
    "            predictions = cam_dicts[model_option][sampling_algorithm][domain_option]\n",
    "            unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "            ind = np.where(unique_counts[0] == domain_option)\n",
    "            predictions = np.hstack((orig_dicts[model_option][sampling_algorithm][domain_option] , predictions))\n",
    "            if len(predictions) > 201:\n",
    "                predictions = predictions[:201]\n",
    "            plt.title('Accuracy vs Shots')\n",
    "            plt.ylabel(\"Accuracy\")\n",
    "            plt.xlabel(\"Number of Shots\")\n",
    "            plt.title('Original')\n",
    "            plt.plot(range(0,len(predictions)), predictions, label=f'{model_option} {sampling_algorithm}')\n",
    "            plt.legend()\n",
    "    \n",
    "out = widgets.interactive_output(f, {'model_options':model_widget, 'domain_option':domain_widget, 'sampling_option': sampling_widget})\n",
    "widgets.HBox([widgets.VBox([model_widget,domain_widget, sampling_widget]), out])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb84d0a-5bf5-4fd7-bf10-d15cfe74c526",
   "metadata": {},
   "source": [
    "iterative: no typicality initial centers, with preclustering, no typicality for future selections\n",
    "weighted: no typicality initial centers, with preclustering, no typicality for future selections\n",
    "iterative_False_True: typicality initial centers, no preclustering, no typicality for future selections\n",
    "dense: no typicality initial centers, with preclustering, typicality for future selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7122981-4773-44cc-a0e2-624a9ad3133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[24,49, 58, -59, 73, -95, 101, 120, 125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609840c-1ee4-4a51-81a9-8abaacb40f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_widget_err = widgets.SelectMultiple(\n",
    "    options=models,\n",
    "    value=['ERM'],\n",
    "    # rows=10,\n",
    "    description='Model:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "domain_widget_err = widgets.Dropdown(\n",
    "    options=all_domains,\n",
    "    value=all_domains[0],\n",
    "    description='Domains:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "sampling_algorithms = list(sampling_algorithms)\n",
    "sampling_widget_err = widgets.SelectMultiple(\n",
    "    options=sampling_algorithms, \n",
    "    #rows=10,\n",
    "    description='Sampling Algorithms',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def g(model_options, sampling_options):\n",
    "    for model_option in model_options:\n",
    "        valid_predictions = []\n",
    "        try:\n",
    "            for sampling_algorithm in sampling_options:\n",
    "                #print(sampling_algorithm)\n",
    "                domain_shot_predictions = [None]*24\n",
    "                for i in range(24):\n",
    "                    domain_shot_predictions[i] = []\n",
    "                for domain_option in cam_dicts[model_option][sampling_algorithm]:\n",
    "                    #print(domain_option)\n",
    "                    if len(cam_dicts[model_option][sampling_algorithm][domain_option]) == 24:\n",
    "                        valid_predictions.append(cam_dicts[model_option][sampling_algorithm][domain_option])\n",
    "                        for num_shot in range(24):\n",
    "                            prediction = cam_dicts[model_option][sampling_algorithm][domain_option][num_shot]\n",
    "                            \n",
    "                            if prediction != -1:\n",
    "                                domain_shot_predictions[num_shot].append(prediction)\n",
    "                means = []\n",
    "                stds = []\n",
    "                for num_shot in range(24):   \n",
    "                    num_shot_predictions = np.vstack(domain_shot_predictions[num_shot])\n",
    "                    num_shot_means = num_shot_predictions.mean(axis=0)[0]\n",
    "                    num_shot_stds = num_shot_predictions.std(axis=0, ddof=1)[0]\n",
    "                    means.append(num_shot_means)\n",
    "                    stds.append(num_shot_stds)\n",
    "                means = np.array(means)\n",
    "                stds = np.array(stds)\n",
    "                #print(means)\n",
    "                plt.plot(range(0,len(means)), means, label=f'{model_option} {sampling_algorithm}')\n",
    "                plt.fill_between(range(0,len(means)), means - stds, means + stds, alpha=0.1)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    if len(model_options) != 0:\n",
    "        plt.legend()\n",
    "\n",
    "out_err = widgets.interactive_output(g, {'model_options':model_widget_err, 'sampling_options':sampling_widget_err})\n",
    "widgets.HBox([widgets.VBox([model_widget_err, sampling_widget_err]), out_err])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d4db8-aef1-401d-aef4-ab4974a17c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def plot(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    print(f'Selecting camera with id {cam_ids[cam_ind]}')\n",
    "    predictions = cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    plt.title('Accuracy vs Shots')\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Number of Shots\")\n",
    "    plt.plot(range(0,len(predictions)), predictions, label='Balanced')\n",
    "    plt.legend()\n",
    "widget = interact(plot, cam_ind=(0,len(good_inds)-1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62fc89-5ac5-41c0-8c3f-f298a92866c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_inds = []\n",
    "for i in range(len(cam_ids)):\n",
    "    predictions = ba_cam_dict[cam_ids[i]]\n",
    "    if predictions[-1] > 0:\n",
    "        good_inds.append(i)\n",
    "def print_green(text, green=True, end='\\n'):\n",
    "    print(f'\\x1b[{32 if green else 31}m{text}\\x1b[0m', end=end)\n",
    "def plot(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    print(f'Selecting camera with id {cam_ids[cam_ind]}')\n",
    "    predictions = ba_cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {ba_orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((ba_orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    plt.title('Balanced Accuracy vs Shots')\n",
    "    plt.xlabel(\"Balanced Accuracy\")\n",
    "    plt.ylabel(\"Number of Shots\")\n",
    "    plt.plot(range(0,len(predictions)), predictions, label='Balanced')\n",
    "    plt.legend()\n",
    "interact(plot, cam_ind=(0,len(good_inds)-1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e22fd-dab4-47f8-accb-b6fc46e6e9a7",
   "metadata": {},
   "source": [
    "## KMeans vs Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a54a70-1801-4132-a0c9-db597ba1af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_dict, orig_dict = get_dict_path('/dccstor/hoo-misha-1/wilds/wilds/results/iwildcam/PseudoLabel')\n",
    "kmeans_cam_dict, kmeans_orig_dict = get_dict_path('/dccstor/hoo-misha-1/wilds/WOODS/notebooks/data/kmeans_closest_batch_classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932c021-95c6-4906-8331-1a61762aeff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = '/dccstor/hoo-misha-1/wilds/wilds/features/iwildcam/PseudoLabel'\n",
    "cam_ids = list(cam_dict.keys() & kmeans_cam_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6582154e-cc77-49bb-a663-dce1f9593334",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_inds = []\n",
    "for i in range(len(cam_ids)):\n",
    "    predictions = cam_dict[cam_ids[i]]\n",
    "    if predictions[-1] > 0:\n",
    "        good_inds.append(i)\n",
    "def print_green(text, green=True, end='\\n'):\n",
    "    print(f'\\x1b[{32 if green else 31}m{text}\\x1b[0m', end=end)\n",
    "def plot(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    print(f'Selecting camera with id {cam_ids[cam_ind]}')\n",
    "    predictions = cam_dict[cam_ids[cam_ind]]\n",
    "    kmeans_predictions = kmeans_cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {orig_dict[cam_ids[cam_ind]]} KMeans Original {kmeans_orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)} KMeans Max {max(kmeans_predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    kmeans_predictions = np.hstack((kmeans_orig_dict[cam_ids[cam_ind]], kmeans_predictions))\n",
    "    plt.plot(range(0,len(predictions)), predictions, label='Uniform')\n",
    "    plt.plot(range(0,len(kmeans_predictions)), kmeans_predictions, label='Kmeans')\n",
    "    plt.legend()\n",
    "    f,l,m = cam_flm(cam_id=[cam_ids[cam_ind]])\n",
    "    label_unique_counts = np.unique(l, return_counts=True)\n",
    "    print(f'Total of {sum(label_unique_counts[1] > 25)} classes over cutoff')\n",
    "    print('[',end='')\n",
    "    for y,c in zip(label_unique_counts[0], label_unique_counts[1]):\n",
    "        print_green(f'{y}:{c}:{c/sum(label_unique_counts[1]):.2f}, ', c > 25, end='')\n",
    "    print(']')\n",
    "interact(plot, cam_ind=(0,len(good_inds)-1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb1ab8-20a1-4593-acd8-d0e824aeef22",
   "metadata": {},
   "source": [
    "## Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd50e3b-e4b0-4bad-9d48-45c6b4e3356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_cam_dict, ba_orig_dict = get_dict_path('/dccstor/hoo-misha-1/wilds/wilds/ba')\n",
    "#ba_kmeans_cam_dict, ba_kmeans_orig_dict = get_dict_path('/dccstor/hoo-misha-1/wilds/WOODS/notebooks/data/ba_kmeans_closest_classes')\n",
    "ba_kmeans_cam_dict, ba_kmeans_orig_dict = get_dict_path('/dccstor/hoo-misha-1/wilds/WOODS/notebooks/data/ba_full_kmeans_closest_batch_classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46fc52-25bc-49c1-8db8-9c222a185ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_inds = []\n",
    "for i in range(len(cam_ids)):\n",
    "    predictions = ba_kmeans_cam_dict[cam_ids[i]]\n",
    "    if predictions[-1] > 0:\n",
    "        good_inds.append(i)\n",
    "\n",
    "def plot(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    print(f'Selecting camera with id {cam_ids[cam_ind]}')\n",
    "    predictions = ba_cam_dict[cam_ids[cam_ind]]\n",
    "    kmeans_predictions = ba_kmeans_cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {ba_orig_dict[cam_ids[cam_ind]]} KMeans Original {ba_kmeans_orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)} KMeans Max {max(kmeans_predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((ba_orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    kmeans_predictions = np.hstack((ba_kmeans_orig_dict[cam_ids[cam_ind]], kmeans_predictions))\n",
    "    plt.plot(range(0,len(predictions)), predictions, label='Uniform')\n",
    "    plt.plot(range(0,len(kmeans_predictions)), kmeans_predictions, label='Kmeans')\n",
    "    plt.legend()\n",
    "    f,l,m = cam_flm(cam_id=[cam_ids[cam_ind]])\n",
    "    label_unique_counts = np.unique(l, return_counts=True)\n",
    "    print(f'Total of {sum(label_unique_counts[1] > 25)} classes over cutoff')\n",
    "    print('[',end='')\n",
    "    for y,c in zip(label_unique_counts[0], label_unique_counts[1]):\n",
    "        print_green(f'{y}:{c}:{c/sum(label_unique_counts[1]):.2f}, ', c > 25, end='')\n",
    "    print(']')\n",
    "interact(plot, cam_ind=(0,len(good_inds)-1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7326649f-5cac-412e-98db-73fbcc60f906",
   "metadata": {},
   "source": [
    "## Iterative Kmeans Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca1452d-7448-4a69-8d1e-6fbf80408226",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_cam_dict, argmax_orig_dict = get_dict_path('/dccstor/hoo-misha-1/wilds/WOODS/notebooks/kmeans_argmax_n_classes')\n",
    "ba_argmax_cam_dict, ba_argmax_orig_dict = get_dict_path('/dccstor/hoo-misha-1/wilds/WOODS/notebooks/ba_kmeans_argmax_n_classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1429d2e-8365-450c-98c6-e5a50e937484",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_inds = []\n",
    "for i in range(len(cam_ids)):\n",
    "    if len(argmax_cam_dict[cam_ids[i]]) == 0:\n",
    "        continue\n",
    "    predictions = argmax_cam_dict[cam_ids[i]]\n",
    "    if predictions[-1] > 0:\n",
    "        good_inds.append(i)\n",
    "\n",
    "def print_green(text, green=True, end='\\n'):\n",
    "    print(f'\\x1b[{32 if green else 31}m{text}\\x1b[0m', end=end)\n",
    "def plot(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    print(f'Selecting camera with id {cam_ids[cam_ind]}')\n",
    "    predictions = argmax_cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {argmax_orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((argmax_orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    plt.plot(range(0,len(predictions)), predictions, label='Iterative')\n",
    "    plt.legend()\n",
    "interact(plot, cam_ind=(0,len(good_inds)-1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeec553-621d-4807-9a41-107570541142",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_inds = []\n",
    "for i in range(len(cam_ids)):\n",
    "    if len(ba_argmax_cam_dict[cam_ids[i]]) == 0:\n",
    "        continue\n",
    "    predictions = ba_argmax_cam_dict[cam_ids[i]]\n",
    "    if predictions[-1] > 0:\n",
    "        good_inds.append(i)\n",
    "\n",
    "def print_green(text, green=True, end='\\n'):\n",
    "    print(f'\\x1b[{32 if green else 31}m{text}\\x1b[0m', end=end)\n",
    "def plot(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    print(f'Selecting camera with id {cam_ids[cam_ind]}')\n",
    "    predictions = ba_argmax_cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {ba_orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((ba_orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    # predictions = np.hstack((ba_argmax_orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    plt.plot(range(0,len(predictions)), predictions, label='Uniform')\n",
    "    plt.legend()\n",
    "interact(plot, cam_ind=(0,len(good_inds)-1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782a899-ed2f-46e3-9569-46ff65da15f4",
   "metadata": {},
   "source": [
    "## Overall Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275a057-1acb-4f0c-90a2-3bc9f0f40f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_ids = list(cam_dict.keys() & kmeans_cam_dict.keys() & argmax_cam_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d803b-c13d-4338-a1b6-6b56d923873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_inds = []\n",
    "for i in range(len(cam_ids)):\n",
    "    predictions = argmax_cam_dict[cam_ids[i]]\n",
    "    if len(predictions) == 0:\n",
    "        continue\n",
    "    if predictions[-1] > 0:\n",
    "        good_inds.append(i)\n",
    "def print_green(text, green=True, end='\\n'):\n",
    "    print(f'\\x1b[{32 if green else 31}m{text}\\x1b[0m', end=end)\n",
    "\n",
    "def plot(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    print(f'Selecting camera with id {cam_ids[cam_ind]}')\n",
    "    predictions = cam_dict[cam_ids[cam_ind]]\n",
    "    kmeans_predictions = kmeans_cam_dict[cam_ids[cam_ind]]\n",
    "    argmax_predictions = argmax_cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {orig_dict[cam_ids[cam_ind]]} KMeans Original {kmeans_orig_dict[cam_ids[cam_ind]]} Iterative Original {argmax_orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)} KMeans Max {max(kmeans_predictions)} Iterative Max {max(argmax_predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    kmeans_predictions = np.hstack((kmeans_orig_dict[cam_ids[cam_ind]], kmeans_predictions))\n",
    "    argmax_predictions = np.hstack((argmax_orig_dict[cam_ids[cam_ind]], argmax_predictions))\n",
    "    plt.title('Accuracy vs Shots')\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Number of Shots\")\n",
    "    plt.plot(range(0,len(predictions)), predictions, label='Balanced')\n",
    "    plt.plot(range(0,len(kmeans_predictions)), kmeans_predictions, label='Kmeans')\n",
    "    plt.plot(range(0,len(argmax_predictions)), argmax_predictions, label='Iterative')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'images/accuracy_{cam_ids[cam_ind]}.png')\n",
    "    f,l,m = cam_flm(cam_id=[cam_ids[cam_ind]])\n",
    "    label_unique_counts = np.unique(l, return_counts=True)\n",
    "    print(f'Total of {sum(label_unique_counts[1] > 25)} classes over cutoff')\n",
    "    print('[',end='')\n",
    "    for y,c in zip(label_unique_counts[0], label_unique_counts[1]):\n",
    "        print_green(f'{y}:{c}:{c/sum(label_unique_counts[1]):.2f}, ', c > 25, end='')\n",
    "    print(']')\n",
    "interact(plot, cam_ind=(0,len(good_inds)-1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c246d2-a0e8-43df-91c8-7284a21d9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_inds = []\n",
    "for i in range(len(cam_ids)):\n",
    "    predictions = ba_argmax_cam_dict[cam_ids[i]]\n",
    "    if len(predictions) == 0:\n",
    "        continue\n",
    "    if predictions[-1] > 0:\n",
    "        good_inds.append(i)\n",
    "def print_green(text, green=True, end='\\n'):\n",
    "    print(f'\\x1b[{32 if green else 31}m{text}\\x1b[0m', end=end)\n",
    "\n",
    "def plot(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    print(f'Selecting camera with id {cam_ids[cam_ind]}')\n",
    "    predictions = ba_cam_dict[cam_ids[cam_ind]]\n",
    "    kmeans_predictions = ba_kmeans_cam_dict[cam_ids[cam_ind]]\n",
    "    argmax_predictions = ba_argmax_cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {ba_orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)} KMeans Max {max(kmeans_predictions)} Iterative Max {max(argmax_predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((ba_orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    kmeans_predictions = np.hstack((ba_orig_dict[cam_ids[cam_ind]], kmeans_predictions))\n",
    "    argmax_predictions = np.hstack((ba_orig_dict[cam_ids[cam_ind]], argmax_predictions))\n",
    "    plt.title('Balanced Accuracy vs Shots')\n",
    "    plt.ylabel(\"Balanced Accuracy\")\n",
    "    plt.xlabel(\"Number of Shots\")\n",
    "    plt.plot(range(0,len(predictions)), predictions, label='Balanced')\n",
    "    plt.plot(range(0,len(kmeans_predictions)), kmeans_predictions, label='Kmeans')\n",
    "    plt.plot(range(0,len(argmax_predictions)), argmax_predictions, label='Iterative')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'images/balanced_accuracy_{cam_ids[cam_ind]}.png')\n",
    "    f,l,m = cam_flm(cam_id=[cam_ids[cam_ind]])\n",
    "    label_unique_counts = np.unique(l, return_counts=True)\n",
    "    print(f'Total of {sum(label_unique_counts[1] > 25)} classes over cutoff')\n",
    "    print('[',end='')\n",
    "    for y,c in zip(label_unique_counts[0], label_unique_counts[1]):\n",
    "        print_green(f'{y}:{c}:{c/sum(label_unique_counts[1]):.2f}, ', c > 25, end='')\n",
    "    print(']')\n",
    "interact(plot, cam_ind=(0,len(good_inds)-1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a40985-4e9d-42b2-ad1d-5cf364e3dbab",
   "metadata": {},
   "source": [
    "## Comparing Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f618a21-042e-456d-b699-ef8a50630ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['ERM', 'PseudoLabel', 'deepCORAL', 'DANN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0522c5-cd77-4ebe-b6f7-26f3f0324034",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dicts = {}\n",
    "ba_model_dicts = {}\n",
    "for model in models:\n",
    "    cam_dict, orig_dict = get_dict_path(f'/dccstor/hoo-misha-1/wilds/WOODS/results/iwildcam/{model}/{model}_iterative')\n",
    "    ba_cam_dict, ba_orig_dict = get_dict_path(f'/dccstor/hoo-misha-1/wilds/WOODS/results/iwildcam/{model}/{model}_balanced')\n",
    "    model_dicts[model] = (cam_dict, orig_dict)\n",
    "    ba_model_dicts[model] = (ba_cam_dict, ba_orig_dict)\n",
    "\n",
    "\n",
    "good_inds = []\n",
    "for i in range(len(cam_ids)):\n",
    "    predictions = model_dicts['ERM'][0][cam_ids[i]]\n",
    "    if len(predictions) == 0:\n",
    "        continue\n",
    "    if predictions[-1] > 0:\n",
    "        good_inds.append(i)    \n",
    "    \n",
    "def plot_4(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    for model in model_dicts:\n",
    "        cam_dict, orig_dict = model_dicts[model]\n",
    "        ba_cam_dict, ba_orig_dict = ba_model_dicts[model]\n",
    "        predictions = cam_dict[cam_ids[cam_ind]]\n",
    "        ba_predictions = ba_cam_dict[cam_ids[cam_ind]]\n",
    "        #print(f'Original {orig_dict[cam_ids[cam_ind]]} Balanced Original {ba_orig_dict[cam_ids[cam_ind]]}')\n",
    "        #print(f'Max {max(predictions)} Balanced Max {max(ba_predictions)}')\n",
    "        metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "        unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "        ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "        #print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "        predictions = np.hstack((orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "        ba_predictions = np.hstack((0, ba_predictions))\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.title('Original')\n",
    "        plt.plot(range(0,len(predictions)), predictions, label=model)\n",
    "        plt.legend()\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.title('Balanced')\n",
    "        plt.plot(range(0,len(ba_predictions)), ba_predictions, label=model)\n",
    "        plt.legend()\n",
    "interact(plot_4, cam_ind=(0,len(good_inds)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57295147-d0d4-4164-bb41-438b7b85e91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
