{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c2c8bd-e564-4281-b583-c6549147d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efdc2147-2862-4ed0-ac8d-5518f68ae394",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(2022)\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0be6a7d-19da-4200-8878-92468a6fdd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepCORAL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('ls /dccstor/hoo-misha-1/wilds/wilds/features/breeds/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40ed020-6114-4f12-a294-007f12477bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_test_features.npy\n",
      "resnet50_test_labels.npy\n",
      "resnet50_test_metadata.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_base = '/dccstor/hoo-misha-1/wilds/wilds/features/breeds/deepCORAL'\n",
    "os.system('ls /dccstor/hoo-misha-1/wilds/wilds/features/breeds/deepCORAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa524084-821a-41a5-9d81-c1e237e4ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flm():\n",
    "    global path_base\n",
    "    test_features = np.load(f'{path_base}/resnet50_test_features.npy')\n",
    "    test_labels = np.load(f'{path_base}/resnet50_test_labels.npy')\n",
    "    test_metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    return test_features, test_labels, test_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "841da4c0-abd1-437a-8a57-0d9613fe7df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_cam_id(cutoff=50):\n",
    "    global path_base\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    return unique_counts[0][unique_counts[1] > cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0767a2a9-a753-4548-9c3a-b0d0cf766d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cam_ind(metadata, num_cams=1, cam_id = None):\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    if cam_id is None:\n",
    "        top_id = unique_counts[0][np.argpartition(unique_counts[1], -num_cams)[-num_cams:]]\n",
    "    else:\n",
    "        top_id = cam_id\n",
    "    print(f'Selecting cameras with ids {top_id}')\n",
    "    ind = np.zeros(metadata.shape[0]) == 1\n",
    "    for c_id in top_id:\n",
    "        ind = np.logical_or(ind,metadata[:,0] == c_id)\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2471854-55a3-4e65-ac93-daaa4a0220ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_flm(num_cams=1, cam_id = None):\n",
    "    features, labels, metadata = load_flm()\n",
    "    cam_ind = get_cam_ind(metadata, num_cams, cam_id)\n",
    "    return features[cam_ind], labels[cam_ind], metadata[cam_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daa3c85d-958a-4228-b298-71bf19ad1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_flm(features, labels, metadata, cutoff=25):\n",
    "    unique_counts = np.unique(labels,return_counts=True)\n",
    "    print(f'|   | Total number of classes {len(unique_counts[0])}')\n",
    "    prune_classes = unique_counts[0][unique_counts[1] < cutoff]\n",
    "    prune_ind = []\n",
    "    for clss in prune_classes:\n",
    "        prune_ind.append((labels == clss).nonzero()[0])\n",
    "    print(f'|   |   | Pruning {len(prune_classes)} classes with {len(np.concatenate(prune_ind))} data points')\n",
    "    if len(prune_ind) == 0:\n",
    "        return features, labels, metadata\n",
    "    prune_ind = np.concatenate(prune_ind)\n",
    "    pruned_ind = np.ones(labels.shape[0]) == 1\n",
    "    pruned_ind[prune_ind] = False\n",
    "    return features[pruned_ind], labels[pruned_ind], metadata[pruned_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15171f91-37ff-4e5d-84cf-6276a96532c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_sample_ind(labels, batch = 5):\n",
    "    unique_classes = np.unique(labels)\n",
    "    #print(unique_classes)\n",
    "    ret_ind = None\n",
    "    for clss in unique_classes:\n",
    "        class_ind = np.where(labels == clss)[0]\n",
    "        #print(clss, class_ind)\n",
    "        rand_ind = rng.choice(class_ind,batch)\n",
    "        if ret_ind is None:\n",
    "            ret_ind = rand_ind\n",
    "        else:\n",
    "            ret_ind = np.concatenate((ret_ind, rand_ind))\n",
    "    return ret_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc020219-1d24-43fa-be20-95a33280c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_closest_batch_classes_sample_ind(features, labels, batch=5, skip_mean=False):\n",
    "    unique_classes = np.unique(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    kmeans = KMeans(n_clusters=batch*num_classes, random_state=random_state).fit(features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    cluster_top = {}\n",
    "    for center_index in range(centers.shape[0]):\n",
    "        center = centers[center_index]\n",
    "        for feature_index in range(features.shape[0]):\n",
    "            feature = features[feature_index]\n",
    "            dist = np.linalg.norm(feature-center)\n",
    "            if skip_mean and center == feature:\n",
    "                    continue\n",
    "            if center_index not in cluster_top:\n",
    "                cluster_top[center_index] = (feature_index, dist)\n",
    "            else:\n",
    "                if cluster_top[center_index][1] < dist:\n",
    "                    cluster_top[center_index] = (feature_index, dist)\n",
    "    ret_ind = []\n",
    "    for center_index, tup in cluster_top.items():\n",
    "        ret_ind.append(tup[0])\n",
    "    return np.array(ret_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "613f1da8-dda3-4611-89ab-1a9080f7fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_closest_classes_sample_ind(features, labels, batch=5):\n",
    "    unique_classes = np.unique(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    kmeans = KMeans(n_clusters=num_classes, random_state=random_state).fit(features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    cluster_top = {}\n",
    "    for center_index in range(centers.shape[0]):\n",
    "        center = centers[center_index]\n",
    "        for feature_index in range(features.shape[0]):\n",
    "            feature = features[feature_index]\n",
    "            dist = np.linalg.norm(feature-center)\n",
    "            if center_index not in cluster_top:\n",
    "                cluster_top[center_index] = [(feature_index, dist)]\n",
    "            else:\n",
    "                # print(cluster_top[center_index])\n",
    "                cluster_top[center_index].append((feature_index, dist))\n",
    "    ret_ind = []\n",
    "    for center_index, tup_list in cluster_top.items():\n",
    "        tup_list.sort(key = lambda x : x[1])\n",
    "        for i in range(batch):\n",
    "            ret_ind.append(tup_list[i][0])\n",
    "       # print(ret_ind)\n",
    "    return np.array(ret_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86d68512-5d39-46b1-9531-b84c301b5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_closest_n_classes_sample_ind(features, labels, batch=5, n=100):\n",
    "    unique_classes = np.unique(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    kmeans = KMeans(n_clusters=n*num_classes, random_state=random_state).fit(features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    cluster_top = {}\n",
    "    for center_index in rng.choice(centers.shape[0], batch*num_classes):\n",
    "        center = centers[center_index]\n",
    "        for feature_index in range(features.shape[0]):\n",
    "            feature = features[feature_index]\n",
    "            dist = np.linalg.norm(feature-center)\n",
    "            if center_index not in cluster_top:\n",
    "                cluster_top[center_index] = (feature_index, dist)\n",
    "            else:\n",
    "                print(cluster_top[center_index])\n",
    "                if cluster_top[center_index][1] < dist:\n",
    "                    cluster_top[center_index] = (feature_index, dist)\n",
    "    ret_ind = []\n",
    "    for center_index, tup in cluster_top.items():\n",
    "        ret_ind.append(tup[0])\n",
    "    return np.array(ret_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25bb198-5c18-4727-93ab-5d8ca87a02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_argmax_n_classes_sample_ind(features, labels, batch=5, n=100):\n",
    "    unique_classes = np.unique(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    \n",
    "    if features.shape[0] > n*num_classes:\n",
    "        batch_classes_kmeans = KMeans(n_clusters=n*num_classes, random_state=random_state).fit(features)\n",
    "        batch_classes_centers = batch_classes_kmeans.cluster_centers_\n",
    "    else:\n",
    "        batch_classes_kmeans = KMeans(n_clusters=num_classes, random_state=random_state).fit(features)\n",
    "        batch_classes_centers = batch_classes_kmeans.cluster_centers_\n",
    "    kmeans = KMeans(n_clusters=num_classes, random_state=random_state).fit(batch_classes_centers)\n",
    "    centers = copy.copy(kmeans.cluster_centers_)\n",
    "    mean_dist = {}\n",
    "    \n",
    "    def get_dist(mu_m, mu_is):\n",
    "        sum_d = 0\n",
    "        for mu_i in mu_is:\n",
    "            sum_d += np.linalg.norm(mu_m - mu_i)\n",
    "        return sum_d\n",
    "    \n",
    "    shots_count = 0\n",
    "    while(shots_count < batch*num_classes):\n",
    "        max_dist = 0\n",
    "        max_dist_i = None\n",
    "        for mu_m_i in range(len(batch_classes_centers)):\n",
    "            mu_m = batch_classes_centers[mu_m_i]\n",
    "            if mu_m in centers:\n",
    "                continue\n",
    "            mu_m_dist = get_dist(mu_m, centers)\n",
    "            if mu_m_dist > max_dist:\n",
    "                max_dist = mu_m_dist\n",
    "                max_dist_i = mu_m_i\n",
    "        \n",
    "        #print(centers.shape)\n",
    "        centers = np.vstack((centers, batch_classes_centers[max_dist_i][np.newaxis,:]))\n",
    "        shots_count += 1\n",
    "        \n",
    "    ret_ind = []  \n",
    "    for center_index in range(centers.shape[0]):\n",
    "        center = centers[center_index]\n",
    "        min_dist = 9999\n",
    "        min_i = None\n",
    "        for feature_index in range(features.shape[0]):\n",
    "            feature = features[feature_index]\n",
    "            dist = np.linalg.norm(feature-center)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                min_i = feature_index\n",
    "        ret_ind.append(min_i)\n",
    "    return np.array(ret_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f0fce5e-9a9d-4cbf-bd91-737be823fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_weighted_argmax_n_classes_sample_ind(features, labels, batch=5, n=100):\n",
    "    unique_classes = np.unique(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    batch_classes_kmeans = KMeans(n_clusters=n*num_classes, random_state=random_state).fit(features)\n",
    "    batch_classes_centers = batch_classes_kmeans.cluster_centers_\n",
    "    kmeans = KMeans(n_clusters=num_classes, random_state=random_state).fit(batch_classes_centers)\n",
    "    centers = copy.copy(kmeans.cluster_centers_)\n",
    "    \n",
    "    batch_classes_center_labels = [-1]*len(batch_classes_center_labels)\n",
    "    center_labels = [-1] * len(centers)\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        feature = features[i]\n",
    "        try:\n",
    "            ii = centers.index(feature)\n",
    "            center_labels[ii] = labels[i]\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            ii = batch_classes_centers.index(feature)\n",
    "            batch_classes_center_labels[ii] = labels[i]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    mean_dist = {}\n",
    "    \n",
    "    def get_dist(mu_m, mu_is):\n",
    "        sum_d = 0\n",
    "        for mu_i in mu_is:\n",
    "            sum_d += np.linalg.norm(mu_m - mu_i)\n",
    "        return sum_d\n",
    "\n",
    "    shots_count = 0\n",
    "    while(shots_count < batch*num_classes):\n",
    "        max_dist = 0\n",
    "        max_dist_i = None\n",
    "        \n",
    "        center_labels_counts = np.unique(center_labels)\n",
    "        \n",
    "        for mu_m_i in range(len(batch_classes_centers)):\n",
    "            \n",
    "            mu_m = batch_classes_centers[mu_m_i]\n",
    "            mu_m_label = batch_classes_center_labels[mu_m_i]\n",
    "\n",
    "            mu_m_label_count_i = center_labels_counts[0].index(mu_m_label)\n",
    "            mu_m_label_count = center_labels_counts[1][mu_m_label_count_i]\n",
    "            \n",
    "            if mu_m in centers:\n",
    "                continue\n",
    "        mu_m_dist = mu_m_label_count / len(center_labels) * get_dist(mu_m, centers)\n",
    "        if mu_m_dist > max_dist:\n",
    "            max_dist = mu_m_dist\n",
    "            max_dist_i = mu_m_i\n",
    "        \n",
    "        np.vstack((centers, batch_classes_centers[max_dist_i][np.newaxis,:]))\n",
    "        centers_labels.append(batch_classes_center_labels[max_dist_i])\n",
    "        ret_ind.append(max_dist_i)\n",
    "        shots_count += 1\n",
    "    \n",
    "    ret_ind = []  \n",
    "    for center_index in range(centers.shape[0]):\n",
    "        center = centers[center_index]\n",
    "        min_dist = 9999\n",
    "        min_i = None\n",
    "        for feature_index in range(features.shape[0]):\n",
    "            feature = features[feature_index]\n",
    "            dist = np.linalg.norm(feature-center)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                min_i = feature_index\n",
    "        ret_ind.append(min_i)\n",
    "        \n",
    "    return np.array(ret_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61c42404-6220-4820-9f3d-5fe0dac58112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_accuracy(sampled_ind, nonsampled_ind, num_cams=1, largest=True, cam_id = None, cutoff = 25):#, batch = 5):\n",
    "    f,l,m = cam_flm(num_cams, cam_id)\n",
    "    f,l,m = prune_flm(f,l,m, cutoff)\n",
    "    # sampled_ind = kmeans_closest_batch_classes_sample_ind(f,l,batch)\n",
    "    # nonsampled_ind = np.ones(l.shape[0]) == 1\n",
    "    # nonsampled_ind[sampled_ind] = False\n",
    "    try:\n",
    "        clf = LogisticRegression(random_state=0,max_iter=100000).fit(f[sampled_ind], l[sampled_ind])\n",
    "        predictions = clf.predict(f[nonsampled_ind])\n",
    "    except Exception as e:\n",
    "        print(f'Count not solve regression {e}')\n",
    "        return -1\n",
    "    \n",
    "    return np.sum(predictions == l[nonsampled_ind])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1303aee7-c040-45d4-9dfb-38a44b649e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_accuracy(num_cams=1, largest=True, cam_id = None, cutoff = 25):\n",
    "    f,l,m = cam_flm(num_cams, cam_id)\n",
    "    f,l,m = prune_flm(f,l,m, cutoff)\n",
    "    weight = np.load('/dccstor/hoo-misha-1/wilds/wilds/pseudo_classifier_weight.npy')\n",
    "    bias = np.load('/dccstor/hoo-misha-1/wilds/wilds/pseudo_classifier_bias.npy')\n",
    "    pred_logits = f @ weight.T + bias\n",
    "    pred = np.argmax(pred_logits,axis=1)\n",
    "    return np.sum(pred == l)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6560da-0730-49c0-aa37-9a29fa00ea68",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_base = '/dccstor/hoo-misha-1/wilds/wilds/features/iwildcam/PseudoLabel'\n",
    "rng = np.random.default_rng(2022)\n",
    "random_state = 0\n",
    "cam_ids = prune_cam_id()\n",
    "print(f'Total {len(cam_ids)} to check')\n",
    "cam_dict = {}\n",
    "orig_dict = {}\n",
    "cutoff = 25\n",
    "for cam_id in cam_ids:\n",
    "    print(f'| Cam ID {cam_id}')\n",
    "    cam_dict[cam_id] = []\n",
    "    orig_dict[cam_id] = get_original_accuracy(cam_id=[cam_id], cutoff=cutoff)\n",
    "    print(f'|   | {orig_dict[cam_id]}')\n",
    "    f,l,m = cam_flm(1, [cam_id])\n",
    "    f,l,m = prune_flm(f,l,m, cutoff)\n",
    "    if f.shape[0] < 500:\n",
    "        continue\n",
    "    # sampled_ind_full = kmeans_closest_classes_sample_ind(f,l,batch=cutoff)\n",
    "    unique_classes = np.unique(l)\n",
    "    num_classes = len(unique_classes)\n",
    "    for batch in range(1,cutoff):\n",
    "        sampled_ind = kmeans_argmax_n_classes_sample_ind(f,l,batch=batch)\n",
    "        print(sampled_ind)\n",
    "        # sampled_ind = sampled_ind_full[:batch*num_classes]\n",
    "        nonsampled_ind = np.ones(l.shape[0]) == 1\n",
    "        nonsampled_ind[sampled_ind] = False\n",
    "        print(f'|   | {batch}')\n",
    "        prediction_acc = 0\n",
    "        c = 0\n",
    "        for i in range(3):\n",
    "            # sampled_ind = kmeans_argmax_n_classes_sample_ind(f,l,batch=batch)\n",
    "            # # sampled_ind = sampled_ind_full[:batch*num_classes]\n",
    "            # nonsampled_ind = np.ones(l.shape[0]) == 1\n",
    "            # nonsampled_ind[sampled_ind] = False\n",
    "            prediction_acc_i = get_prediction_accuracy(sampled_ind, nonsampled_ind,cam_id = [cam_id], cutoff=cutoff)#, batch=batch)\n",
    "            if prediction_acc_i >= 0:\n",
    "                prediction_acc += prediction_acc_i\n",
    "                c += 1\n",
    "        if c != 0:\n",
    "            prediction_acc/= c\n",
    "        else:\n",
    "            prediction_acc = -1\n",
    "        print(f'|   | {prediction_acc}')\n",
    "        cam_dict[cam_id].append(prediction_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c62cb1-5507-4c27-a62f-9eaab373079e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cam_ids = prune_cam_id()\n",
    "# print(f'Total {len(cam_ids)} to check')\n",
    "# cam_dict = {}\n",
    "# orig_dict = {}\n",
    "# cutoff = 25\n",
    "# for cam_id in cam_ids:\n",
    "#     print(f'| Cam ID {cam_id}')\n",
    "#     cam_dict[cam_id] = []\n",
    "#     orig_dict[cam_id] = get_original_accuracy(cam_id=[cam_id], cutoff=cutoff)\n",
    "#     print(f'|   | {orig_dict[cam_id]}')\n",
    "#     for batch in range(1,cutoff):\n",
    "#         print(f'|   | {batch}')\n",
    "#         prediction_acc = 0\n",
    "#         for i in range(3):\n",
    "#             prediction_acc += get_prediction_accuracy(cam_id = [cam_id], cutoff=cutoff, batch=batch)\n",
    "#         prediction_acc /= 3\n",
    "#         print(f'|   | {prediction_acc}')\n",
    "#         cam_dict[cam_id].append(prediction_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b39c1f5-f250-4d68-8b28-b23b258d9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_dict(model):\n",
    "    root_path = '/dccstor/hoo-misha-1/wilds/wilds/results/iwildcam'\n",
    "    base_path = f'{root_path}/{model}'\n",
    "    \n",
    "    with open(f'{base_path}_cam_dict.pkl','rb') as file:\n",
    "        cam_dict = pickle.load(file)\n",
    "\n",
    "    with open(f'{base_path}_orig_dict.pkl','rb') as file:\n",
    "        orig_dict = pickle.load(file)\n",
    "    \n",
    "    return cam_dict, orig_dict\n",
    "\n",
    "def get_dict_path(root_path):\n",
    "    cam_dict_path = f'{root_path}/kmeans_closest_batch_classes_cam_dict.pkl'\n",
    "    orig_dict_path = f'{root_path}/kmeans_closest_batch_classes_orig_dict.pkl'\n",
    "    \n",
    "    with open(cam_dict_path,'rb') as file:\n",
    "        cam_dict = pickle.load(file)\n",
    "\n",
    "    with open(orig_dict_path,'rb') as file:\n",
    "        orig_dict = pickle.load(file)\n",
    "    \n",
    "    return cam_dict, orig_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "734dbc18-42dd-4b7a-a0b6-d51babc21a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_dict, orig_dict = get_dict_path('/dccstor/hoo-misha-1/wilds/WOODS/notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5eb72f18-34e4-40aa-9df4-c011023c35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_ids = prune_cam_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e3631bf3-2704-43b5-86be-71e16a64685e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca6ee77b1c14ed4b2b239be380848ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=17, description='cam_ind', max=35), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(cam_ind):\n",
    "    predictions = cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    plt.plot(range(0,len(predictions)), predictions)\n",
    "    \n",
    "interact(plot, cam_ind=(0,len(cam_ids)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61583041-060c-4d37-bba7-a9f3e26bcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "good_inds = []\n",
    "for i in range(len(cam_ids)):\n",
    "    predictions = cam_dict[cam_ids[i]]\n",
    "    if predictions[-1] > 0:\n",
    "        good_inds.append(i)\n",
    "        \n",
    "def plot_2(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    print(f'Camera id {cam_ids[cam_ind]}')\n",
    "    predictions = cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    plt.plot(range(0,len(predictions)), predictions)\n",
    "\n",
    "\n",
    "interact(plot_2, cam_ind=(0,len(good_inds)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a60dc5b6-3ef8-42e3-996a-b1696cd70054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8dbc61d7e94882a6ba3d06ccb633a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=17, description='cam_ind', max=34), IntSlider(value=25, description='cut…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_green(text, green=True, end='\\n'):\n",
    "    print(f'\\x1b[{32 if green else 31}m{text}\\x1b[0m', end=end)\n",
    "def show_dist(cam_ind, cutoff=25):\n",
    "    f,l,m = cam_flm(cam_id=[cam_ids[cam_ind]])\n",
    "    unique_counts = np.unique(l, return_counts=True)\n",
    "    print(f'Total of {sum(unique_counts[1] > cutoff)} classes over cutoff')\n",
    "    print('[',end='')\n",
    "    for y,c in zip(unique_counts[0], unique_counts[1]):\n",
    "        print_green(f'{y}:{c}:{c/sum(unique_counts[1]):.2f}, ', c > cutoff, end='')\n",
    "    print(']')\n",
    "\n",
    "interact(show_dist, cam_ind=(0,len(cam_ids)-1), cutoff=(10,500));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aea3aaeb-ecd6-43d4-a009-4ffc54608ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa524fe0ac4e46d38d3f5dad4489300f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='model_ind', max=5), IntSlider(value=10, description='cam…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_path = '/dccstor/hoo-misha-1/wilds/wilds/features/iwildcam'\n",
    "models = list(os.listdir(root_path))\n",
    "\n",
    "def plot_3(model_ind, cam_ind):\n",
    "    global cam_dict, orig_dict\n",
    "    model = models[model_ind]\n",
    "    print(f'Using {model}')\n",
    "    cam_dict, orig_dict = get_dict(model)\n",
    "    plot_2(cam_ind)\n",
    "\n",
    "interact(plot_3, model_ind=(0,len(models)-1), cam_ind=(0,len(good_inds)-1));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acccb69-655a-4eff-8a22-c3ff8d759ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('kmeans_argmax_cam_dict.pkl','wb') as file:\n",
    "    pickle.dump(cam_dict, file)\n",
    "    \n",
    "with open('kmeans_argmax_n_classes_orig_dict.pkl','wb') as file:\n",
    "    pickle.dump(orig_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366d97a-7daa-4098-a16f-bf19ab4b48b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
