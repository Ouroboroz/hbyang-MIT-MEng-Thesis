{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c2c8bd-e564-4281-b583-c6549147d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efdc2147-2862-4ed0-ac8d-5518f68ae394",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(2022)\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0be6a7d-19da-4200-8878-92468a6fdd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFN\n",
      "DANN\n",
      "deepCORAL\n",
      "ERM\n",
      "FixMatch\n",
      "PseudoLabel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('ls /dccstor/hoo-misha-1/wilds/wilds/features/iwildcam/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e40ed020-6114-4f12-a294-007f12477bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_id_test_features.npy\n",
      "resnet50_id_test_labels.npy\n",
      "resnet50_id_test_metadata.npy\n",
      "resnet50_id_val_features.npy\n",
      "resnet50_id_val_labels.npy\n",
      "resnet50_id_val_metadata.npy\n",
      "resnet50_test_features.npy\n",
      "resnet50_test_labels.npy\n",
      "resnet50_test_metadata.npy\n",
      "resnet50_train_features.npy\n",
      "resnet50_train_labels.npy\n",
      "resnet50_train_metadata.npy\n",
      "resnet50_val_features.npy\n",
      "resnet50_val_labels.npy\n",
      "resnet50_val_metadata.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_base = '/dccstor/hoo-misha-1/wilds/wilds/features/iwildcam/PseudoLabel'\n",
    "os.system('ls /dccstor/hoo-misha-1/wilds/wilds/features/iwildcam/PseudoLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa524084-821a-41a5-9d81-c1e237e4ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flm():\n",
    "    test_features = np.load(f'{path_base}/resnet50_test_features.npy')\n",
    "    test_labels = np.load(f'{path_base}/resnet50_test_labels.npy')\n",
    "    test_metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    return test_features, test_labels, test_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "841da4c0-abd1-437a-8a57-0d9613fe7df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_cam_id(cutoff=50):\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    return unique_counts[0][unique_counts[1] > cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0767a2a9-a753-4548-9c3a-b0d0cf766d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cam_ind(metadata, num_cams=1, cam_id = None):\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    if cam_id is None:\n",
    "        top_id = unique_counts[0][np.argpartition(unique_counts[1], -num_cams)[-num_cams:]]\n",
    "    else:\n",
    "        top_id = cam_id\n",
    "    print(f'Selecting cameras with ids {top_id}')\n",
    "    ind = np.zeros(metadata.shape[0]) == 1\n",
    "    for c_id in top_id:\n",
    "        ind = np.logical_or(ind,metadata[:,0] == c_id)\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2471854-55a3-4e65-ac93-daaa4a0220ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_flm(num_cams=1, cam_id = None):\n",
    "    features, labels, metadata = load_flm()\n",
    "    cam_ind = get_cam_ind(metadata, num_cams, cam_id)\n",
    "    return features[cam_ind], labels[cam_ind], metadata[cam_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "daa3c85d-958a-4228-b298-71bf19ad1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_flm(features, labels, metadata, cutoff=25):\n",
    "    unique_counts = np.unique(labels,return_counts=True)\n",
    "    print(f'|   | Total number of classes {len(unique_counts[0])}')\n",
    "    prune_classes = unique_counts[0][unique_counts[1] < cutoff]\n",
    "    prune_ind = []\n",
    "    for clss in prune_classes:\n",
    "        prune_ind.append((labels == clss).nonzero()[0])\n",
    "    print(f'|   |   | Pruning {len(prune_classes)} classes with {len(np.concatenate(prune_ind))} data points')\n",
    "    if len(prune_ind) == 0:\n",
    "        return features, labels, metadata\n",
    "    prune_ind = np.concatenate(prune_ind)\n",
    "    pruned_ind = np.ones(labels.shape[0]) == 1\n",
    "    pruned_ind[prune_ind] = False\n",
    "    return features[pruned_ind], labels[pruned_ind], metadata[pruned_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15171f91-37ff-4e5d-84cf-6276a96532c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_sample_ind(labels, batch = 5):\n",
    "    unique_classes = np.unique(labels)\n",
    "    #print(unique_classes)\n",
    "    ret_ind = None\n",
    "    for clss in unique_classes:\n",
    "        class_ind = np.where(labels == clss)[0]\n",
    "        #print(clss, class_ind)\n",
    "        rand_ind = rng.choice(class_ind,batch)\n",
    "        if ret_ind is None:\n",
    "            ret_ind = rand_ind\n",
    "        else:\n",
    "            ret_ind = np.concatenate((ret_ind, rand_ind))\n",
    "    return ret_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc020219-1d24-43fa-be20-95a33280c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_closest_batch_classes_sample_ind(features, labels, batch=5, skip_mean=False):\n",
    "    unique_classes = np.unique(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    kmeans = KMeans(n_clusters=batch*num_classes, random_state=random_state).fit(features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    cluster_top = {}\n",
    "    for center_index in range(centers.shape[0]):\n",
    "        center = centers[center_index]\n",
    "        for feature_index in range(features.shape[0]):\n",
    "            feature = features[feature_index]\n",
    "            dist = np.linalg.norm(feature-center)\n",
    "            if skip_mean and center == feature:\n",
    "                    continue\n",
    "            if center_index not in cluster_top:\n",
    "                cluster_top[center_index] = (feature_index, dist)\n",
    "            else:\n",
    "                if cluster_top[center_index][1] < dist:\n",
    "                    cluster_top[center_index] = (feature_index, dist)\n",
    "    ret_ind = []\n",
    "    for center_index, tup in cluster_top.items():\n",
    "        ret_ind.append(tup[0])\n",
    "    return np.array(ret_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "613f1da8-dda3-4611-89ab-1a9080f7fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_closest_classes_sample_ind(features, labels, batch=5):\n",
    "    unique_classes = np.unique(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    kmeans = KMeans(n_clusters=num_classes, random_state=random_state).fit(features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    cluster_top = {}\n",
    "    for center_index in range(centers.shape[0]):\n",
    "        center = centers[center_index]\n",
    "        for feature_index in range(features.shape[0]):\n",
    "            feature = features[feature_index]\n",
    "            dist = np.linalg.norm(feature-center)\n",
    "            if center_index not in cluster_top:\n",
    "                cluster_top[center_index] = [(feature_index, dist)]\n",
    "            else:\n",
    "                # print(cluster_top[center_index])\n",
    "                cluster_top[center_index].append((feature_index, dist))\n",
    "    ret_ind = []\n",
    "    for center_index, tup_list in cluster_top.items():\n",
    "        tup_list.sort(key = lambda x : x[1])\n",
    "        for i in range(batch):\n",
    "            ret_ind.append(tup_list[i][0])\n",
    "       # print(ret_ind)\n",
    "    return np.array(ret_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86d68512-5d39-46b1-9531-b84c301b5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_closest_n_classes_sample_ind(features, labels, batch=5, n=100):\n",
    "    unique_classes = np.unique(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    kmeans = KMeans(n_clusters=n*num_classes, random_state=random_state).fit(features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    cluster_top = {}\n",
    "    for center_index in rng.choice(centers.shape[0], batch*num_classes):\n",
    "        center = centers[center_index]\n",
    "        for feature_index in range(features.shape[0]):\n",
    "            feature = features[feature_index]\n",
    "            dist = np.linalg.norm(feature-center)\n",
    "            if center_index not in cluster_top:\n",
    "                cluster_top[center_index] = (feature_index, dist)\n",
    "            else:\n",
    "                print(cluster_top[center_index])\n",
    "                if cluster_top[center_index][1] < dist:\n",
    "                    cluster_top[center_index] = (feature_index, dist)\n",
    "    ret_ind = []\n",
    "    for center_index, tup in cluster_top.items():\n",
    "        ret_ind.append(tup[0])\n",
    "    return np.array(ret_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f25bb198-5c18-4727-93ab-5d8ca87a02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_argmax_n_classes_sample_ind(features, labels, batch=5, n=100):\n",
    "    unique_classes = np.unique(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    \n",
    "    if features.shape[0] > n*num_classes:\n",
    "        batch_classes_kmeans = KMeans(n_clusters=n*num_classes, random_state=random_state).fit(features)\n",
    "        batch_classes_centers = batch_classes_kmeans.cluster_centers_\n",
    "    else:\n",
    "        batch_classes_kmeans = KMeans(n_clusters=num_classes, random_state=random_state).fit(features)\n",
    "        batch_classes_centers = batch_classes_kmeans.cluster_centers_\n",
    "    kmeans = KMeans(n_clusters=num_classes, random_state=random_state).fit(batch_classes_centers)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    mean_dist = {}\n",
    "    \n",
    "    def get_dist(mu_m, mu_is):\n",
    "        sum_d = 0\n",
    "        for mu_i in mu_is:\n",
    "            sum_d += np.linalg.norm(mu_m - mu_i)\n",
    "        return sum_d\n",
    "    \n",
    "    for mu_m_i in range(len(batch_classes_centers)):\n",
    "        mu_m = batch_classes_centers[mu_m_i]\n",
    "        if mu_m in centers:\n",
    "            continue\n",
    "        mean_dist[mu_m_i] = get_dist(mu_m, batch_classes_centers)\n",
    "    \n",
    "    mean_dist_tups = list(mean_dist.items())\n",
    "    mean_dist_tups.sort(key=lambda x : x[1],reverse=True)\n",
    "    ret_ind = []\n",
    "    for i in range(batch*num_classes):\n",
    "        ret_ind.append(mean_dist_tups[i][0])\n",
    "    return np.array(ret_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f0fce5e-9a9d-4cbf-bd91-737be823fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_weighted_argmax_n_classes_sample_ind(features, labels, batch=5, n=100):\n",
    "    unique_classes = np.unique(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    batch_classes_kmeans = KMeans(n_clusters=n*num_classes, random_state=random_state).fit(features)\n",
    "    batch_classes_centers = batch_classes_kmeans.cluster_centers_\n",
    "    kmeans = KMeans(n_clusters=num_classes, random_state=random_state).fit(batch_classes_centers)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    \n",
    "    batch_classes_center_labels = [-1]*len(batch_classes_center_labels)\n",
    "    center_labels = [-1] * len(centers)\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        feature = features[i]\n",
    "        try:\n",
    "            ii = centers.index(feature)\n",
    "            center_labels[ii] = labels[i]\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            ii = batch_classes_centers.index(feature)\n",
    "            batch_classes_center_labels[ii] = labels[i]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    mean_dist = {}\n",
    "    \n",
    "    def get_dist(mu_m, mu_is):\n",
    "        sum_d = 0\n",
    "        for mu_i in mu_is:\n",
    "            sum_d += np.linalg.norm(mu_m - mu_i)\n",
    "        return sum_d\n",
    "    \n",
    "    center_labels_counts = np.unique(center_labels)\n",
    "    \n",
    "    for mu_m_i in range(len(batch_classes_centers)):\n",
    "        mu_m = batch_classes_centers[mu_m_i]\n",
    "        mu_m_label = batch_classes_center_labels[mu_m_i]\n",
    "        \n",
    "        mu_m_label_count_i = center_labels_counts[0].index(mu_m_label)\n",
    "        mu_m_label_count = center_labels_counts[1][mu_m_label_count_i]\n",
    "        \n",
    "        if mu_m in centers:\n",
    "            continue\n",
    "        mean_dist[mu_m_i] = mu_m_label_count / len(center_labels) * get_dist(mu_m, batch_classes_kmeans)\n",
    "    \n",
    "    mean_dist_tups = list(mean_dist.items())\n",
    "    mean_dist_tups.sort(key=lambda x : x[1],reverse=True)\n",
    "    ret_ind = []\n",
    "    for i in range(batch*num_classes):\n",
    "        ret_ind.append(mean_dist_tups[i][0])\n",
    "    return np.array(ret_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61c42404-6220-4820-9f3d-5fe0dac58112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_accuracy(sampled_ind, nonsampled_ind, num_cams=1, largest=True, cam_id = None, cutoff = 25):#, batch = 5):\n",
    "    f,l,m = cam_flm(num_cams, cam_id)\n",
    "    f,l,m = prune_flm(f,l,m, cutoff)\n",
    "    # sampled_ind = kmeans_closest_batch_classes_sample_ind(f,l,batch)\n",
    "    # nonsampled_ind = np.ones(l.shape[0]) == 1\n",
    "    # nonsampled_ind[sampled_ind] = False\n",
    "    try:\n",
    "        clf = LogisticRegression(random_state=0,max_iter=2000).fit(f[sampled_ind], l[sampled_ind])\n",
    "        predictions = clf.predict(f[nonsampled_ind])\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "    return np.sum(predictions == l[nonsampled_ind])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7704987b-eeaa-44c5-b4ca-43ae06c34a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_accuracy(sampled_ind, nonsampled_ind, num_cams=1, largest=True, cam_id = None, cutoff = 25, batch = 5):\n",
    "    f,l,m = cam_flm(num_cams, cam_id)\n",
    "    f,l,m = prune_flm(f,l,m, cutoff)\n",
    "    # sampled_ind = balanced_sample_ind(l,batch)\n",
    "    # nonsampled_ind = np.ones(l.shape[0]) == 1\n",
    "    # nonsampled_ind[sampled_ind] = False\n",
    "    try:\n",
    "        clf = LogisticRegression(random_state=0,max_iter=2000).fit(f[sampled_ind], l[sampled_ind])\n",
    "        predictions = clf.predict(f[nonsampled_ind])\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        return -1\n",
    "    \n",
    "    return balanced_accuracy_score(l[nonsampled_ind], predictions)#, f1_score(l[nonsampled_ind], predictions,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1303aee7-c040-45d4-9dfb-38a44b649e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_accuracy(num_cams=1, largest=True, cam_id = None, cutoff = 25):\n",
    "    f,l,m = cam_flm(num_cams, cam_id)\n",
    "    f,l,m = prune_flm(f,l,m, cutoff)\n",
    "    weight = np.load('/dccstor/hoo-misha-1/wilds/wilds/pseudo_classifier_weight.npy')\n",
    "    bias = np.load('/dccstor/hoo-misha-1/wilds/wilds/pseudo_classifier_bias.npy')\n",
    "    pred_logits = f @ weight.T + bias\n",
    "    pred = np.argmax(pred_logits,axis=1)\n",
    "    return np.sum(pred == l)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b16cedb-621a-4d20-9acb-45d725f4b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_original_accuracy(num_cams=1, largest=True, cam_id = None, cutoff = 25):\n",
    "    f,l,m = cam_flm(num_cams, cam_id)\n",
    "    f,l,m = prune_flm(f,l,m, cutoff)\n",
    "    weight = np.load('/dccstor/hoo-misha-1/wilds/wilds/pseudo_classifier_weight.npy')\n",
    "    bias = np.load('/dccstor/hoo-misha-1/wilds/wilds/pseudo_classifier_bias.npy')\n",
    "    pred_logits = f @ weight.T + bias\n",
    "    pred = np.argmax(pred_logits,axis=1)\n",
    "    return balanced_accuracy_score(l, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c6560da-0730-49c0-aa37-9a29fa00ea68",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cam_ids \u001b[38;5;241m=\u001b[39m \u001b[43mprune_cam_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cam_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to check\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m cam_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mprune_cam_id\u001b[0;34m(cutoff)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprune_cam_id\u001b[39m(cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_base\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/resnet50_test_metadata.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m     unique_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(metadata[:,\u001b[38;5;241m0\u001b[39m],return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unique_counts[\u001b[38;5;241m0\u001b[39m][unique_counts[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m cutoff]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_base' is not defined"
     ]
    }
   ],
   "source": [
    "cam_ids = prune_cam_id()\n",
    "print(f'Total {len(cam_ids)} to check')\n",
    "cam_dict = {}\n",
    "orig_dict = {}\n",
    "cutoff = 25\n",
    "for cam_id in cam_ids:\n",
    "    print(f'| Cam ID {cam_id}')\n",
    "    cam_dict[cam_id] = []\n",
    "    orig_dict[cam_id] = get_balanced_original_accuracy(cam_id=[cam_id], cutoff=cutoff)\n",
    "    print(f'|   | {orig_dict[cam_id]}')\n",
    "    f,l,m = cam_flm(1, [cam_id])\n",
    "    f,l,m = prune_flm(f,l,m, cutoff)\n",
    "    # sampled_ind_full = kmeans_closest_batch_classes_sample_ind(f,l,batch=cutoff)\n",
    "    unique_classes = np.unique(l)\n",
    "    num_classes = len(unique_classes)\n",
    "    for batch in range(1,cutoff):\n",
    "        sampled_ind_full = kmeans_closest_batch_classes_sample_ind(f,l,batch=batch)\n",
    "        sampled_ind = sampled_ind_full#[:batch*num_classes]\n",
    "        nonsampled_ind = np.ones(l.shape[0]) == 1\n",
    "        nonsampled_ind[sampled_ind] = False\n",
    "        print(f'|   | {batch}')\n",
    "        prediction_acc = 0\n",
    "        for i in range(3):\n",
    "            prediction_acc += get_balanced_accuracy(sampled_ind, nonsampled_ind,cam_id = [cam_id], cutoff=cutoff)#, batch=batch)\n",
    "        prediction_acc /= 3\n",
    "        print(f'|   | {prediction_acc}')\n",
    "        cam_dict[cam_id].append(prediction_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77c62cb1-5507-4c27-a62f-9eaab373079e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cam_ids = prune_cam_id()\n",
    "# print(f'Total {len(cam_ids)} to check')\n",
    "# cam_dict = {}\n",
    "# orig_dict = {}\n",
    "# cutoff = 25\n",
    "# for cam_id in cam_ids:\n",
    "#     print(f'| Cam ID {cam_id}')\n",
    "#     cam_dict[cam_id] = []\n",
    "#     orig_dict[cam_id] = get_original_accuracy(cam_id=[cam_id], cutoff=cutoff)\n",
    "#     print(f'|   | {orig_dict[cam_id]}')\n",
    "#     for batch in range(1,cutoff):\n",
    "#         print(f'|   | {batch}')\n",
    "#         prediction_acc = 0\n",
    "#         for i in range(3):\n",
    "#             prediction_acc += get_prediction_accuracy(cam_id = [cam_id], cutoff=cutoff, batch=batch)\n",
    "#         prediction_acc /= 3\n",
    "#         print(f'|   | {prediction_acc}')\n",
    "#         cam_dict[cam_id].append(prediction_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b39c1f5-f250-4d68-8b28-b23b258d9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_dict(model):\n",
    "    root_path = '/dccstor/hoo-misha-1/wilds/wilds/results/iwildcam'\n",
    "    base_path = f'{root_path}/{model}'\n",
    "    \n",
    "    with open(f'{base_path}_cam_dict.pkl','rb') as file:\n",
    "        cam_dict = pickle.load(file)\n",
    "\n",
    "    with open(f'{base_path}_orig_dict.pkl','rb') as file:\n",
    "        orig_dict = pickle.load(file)\n",
    "    \n",
    "    return cam_dict, orig_dict\n",
    "\n",
    "def get_dict_path(root_path):\n",
    "    cam_dict_path = f'{root_path}/kmeans_closest_batch_classes_cam_dict.pkl'\n",
    "    orig_dict_path = f'{root_path}/kmeans_closest_batch_classes_orig_dict.pkl'\n",
    "    \n",
    "    with open(cam_dict_path,'rb') as file:\n",
    "        cam_dict = pickle.load(file)\n",
    "\n",
    "    with open(orig_dict_path,'rb') as file:\n",
    "        orig_dict = pickle.load(file)\n",
    "    \n",
    "    return cam_dict, orig_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "734dbc18-42dd-4b7a-a0b6-d51babc21a5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dccstor/hoo-misha-1/wilds/WOODS/notebooks/kmeans_closest_batch_classes_cam_dict.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cam_dict, orig_dict \u001b[38;5;241m=\u001b[39m \u001b[43mget_dict_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/dccstor/hoo-misha-1/wilds/WOODS/notebooks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36mget_dict_path\u001b[0;34m(root_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m cam_dict_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/kmeans_closest_batch_classes_cam_dict.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m orig_dict_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/kmeans_closest_batch_classes_orig_dict.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcam_dict_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     20\u001b[0m     cam_dict \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(orig_dict_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dccstor/hoo-misha-1/wilds/WOODS/notebooks/kmeans_closest_batch_classes_cam_dict.pkl'"
     ]
    }
   ],
   "source": [
    "cam_dict, orig_dict = get_dict_path('/dccstor/hoo-misha-1/wilds/WOODS/notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5eb72f18-34e4-40aa-9df4-c011023c35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_ids = prune_cam_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3631bf3-2704-43b5-86be-71e16a64685e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b074217f3f84fd7847e01b38e06d8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=17, description='cam_ind', max=35), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(cam_ind):\n",
    "    predictions = cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    plt.plot(range(0,len(predictions)), predictions)\n",
    "    \n",
    "interact(plot, cam_ind=(0,len(cam_ids)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61583041-060c-4d37-bba7-a9f3e26bcd0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cam_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m good_inds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(cam_ids)):\n\u001b[0;32m----> 6\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mcam_dict\u001b[49m[cam_ids[i]]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predictions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      8\u001b[0m         good_inds\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cam_dict' is not defined"
     ]
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "good_inds = []\n",
    "for i in range(len(cam_ids)):\n",
    "    predictions = cam_dict[cam_ids[i]]\n",
    "    if predictions[-1] > 0:\n",
    "        good_inds.append(i)\n",
    "        \n",
    "def plot_2(cam_ind):\n",
    "    cam_ind = good_inds[cam_ind]\n",
    "    print(f'Camera id {cam_ids[cam_ind]}')\n",
    "    predictions = cam_dict[cam_ids[cam_ind]]\n",
    "    print(f'Original {orig_dict[cam_ids[cam_ind]]}')\n",
    "    print(f'Max {max(predictions)}')\n",
    "    metadata = np.load(f'{path_base}/resnet50_test_metadata.npy')\n",
    "    unique_counts = np.unique(metadata[:,0],return_counts=True)\n",
    "    ind = np.where(unique_counts[0] == cam_ids[cam_ind])\n",
    "    print(f'With {unique_counts[1][ind]} data points pre-pruning')\n",
    "    predictions = np.hstack((orig_dict[cam_ids[cam_ind]] , predictions))\n",
    "    plt.plot(range(0,len(predictions)), predictions)\n",
    "\n",
    "\n",
    "interact(plot_2, cam_ind=(0,len(good_inds)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a60dc5b6-3ef8-42e3-996a-b1696cd70054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1fbd8e07b84b42b26b9533097d4e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=17, description='cam_ind', max=34), IntSlider(value=25, description='cut…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_green(text, green=True, end='\\n'):\n",
    "    print(f'\\x1b[{32 if green else 31}m{text}\\x1b[0m', end=end)\n",
    "def show_dist(cam_ind, cutoff=25):\n",
    "    f,l,m = cam_flm(cam_id=[cam_ids[cam_ind]])\n",
    "    unique_counts = np.unique(l, return_counts=True)\n",
    "    print(f'Total of {sum(unique_counts[1] > cutoff)} classes over cutoff')\n",
    "    print('[',end='')\n",
    "    for y,c in zip(unique_counts[0], unique_counts[1]):\n",
    "        print_green(f'{y}:{c}:{c/sum(unique_counts[1]):.2f}, ', c > cutoff, end='')\n",
    "    print(']')\n",
    "\n",
    "interact(show_dist, cam_ind=(0,len(cam_ids)-1), cutoff=(10,500));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aea3aaeb-ecd6-43d4-a009-4ffc54608ab3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "value must be between min and max (min=0, value=-1, max=-1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     cam_dict, orig_dict \u001b[38;5;241m=\u001b[39m get_dict(model)\n\u001b[1;32m      9\u001b[0m     plot_2(cam_ind)\n\u001b[0;32m---> 11\u001b[0m \u001b[43minteract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcam_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgood_inds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/wilds/lib/python3.8/site-packages/ipywidgets/widgets/interaction.py:529\u001b[0m, in \u001b[0;36m_InteractFactory.__call__\u001b[0;34m(self, _InteractFactory__interact_f, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# positional arg support in: https://gist.github.com/8851331\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;66;03m# Handle the cases 1 and 2\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# 1. interact(f, **kwargs)\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;66;03m# 2. @interact\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m#    def f(*args, **kwargs):\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m#        ...\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    531\u001b[0m     f\u001b[38;5;241m.\u001b[39mwidget \u001b[38;5;241m=\u001b[39m w\n",
      "File \u001b[0;32m~/.conda/envs/wilds/lib/python3.8/site-packages/ipywidgets/widgets/interaction.py:445\u001b[0m, in \u001b[0;36m_InteractFactory.widget\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwidget\u001b[39m(\u001b[38;5;28mself\u001b[39m, f):\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    Return an interactive function widget for the given function.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m        The function to which the interactive widgets are tied.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/wilds/lib/python3.8/site-packages/ipywidgets/widgets/interaction.py:201\u001b[0m, in \u001b[0;36minteractive.__init__\u001b[0;34m(self, _interactive__interact_f, _interactive__options, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     getcallargs(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{n:v \u001b[38;5;28;01mfor\u001b[39;00m n,v,_ \u001b[38;5;129;01min\u001b[39;00m new_kwargs})\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# Now build the widgets from the abbreviations.\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs_widgets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidgets_from_abbreviations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# This has to be done as an assignment, not using self.children.append,\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# so that traitlets notices the update. We skip any objects (such as fixed) that\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# are not DOMWidgets.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m c \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs_widgets \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, DOMWidget)]\n",
      "File \u001b[0;32m~/.conda/envs/wilds/lib/python3.8/site-packages/ipywidgets/widgets/interaction.py:298\u001b[0m, in \u001b[0;36minteractive.widgets_from_abbreviations\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    296\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, abbrev, default \u001b[38;5;129;01min\u001b[39;00m seq:\n\u001b[0;32m--> 298\u001b[0m     widget \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidget_from_abbrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabbrev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(widget, ValueWidget) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(widget, fixed)):\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m widget \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/wilds/lib/python3.8/site-packages/ipywidgets/widgets/interaction.py:317\u001b[0m, in \u001b[0;36minteractive.widget_from_abbrev\u001b[0;34m(cls, abbrev, default)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m abbrev\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(abbrev, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 317\u001b[0m     widget \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidget_from_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabbrev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m empty:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/wilds/lib/python3.8/site-packages/ipywidgets/widgets/interaction.py:366\u001b[0m, in \u001b[0;36minteractive.widget_from_tuple\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"Make widgets from a tuple abbreviation.\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _matches(o, (Real, Real)):\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mmax\u001b[39m, value \u001b[38;5;241m=\u001b[39m \u001b[43m_get_min_max_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(_, Integral) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m o):\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m IntSlider\n",
      "File \u001b[0;32m~/.conda/envs/wilds/lib/python3.8/site-packages/ipywidgets/widgets/interaction.py:128\u001b[0m, in \u001b[0;36m_get_min_max_value\u001b[0;34m(min, max, value, step)\u001b[0m\n\u001b[1;32m    126\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m \u001b[38;5;241m+\u001b[39m tick \u001b[38;5;241m*\u001b[39m step\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mmin\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m value \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue must be between min and max (min=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, value=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m, max=\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mmin\u001b[39m, value, \u001b[38;5;28mmax\u001b[39m))\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mmax\u001b[39m, value\n",
      "\u001b[0;31mValueError\u001b[0m: value must be between min and max (min=0, value=-1, max=-1)"
     ]
    }
   ],
   "source": [
    "root_path = '/dccstor/hoo-misha-1/wilds/wilds/features/iwildcam'\n",
    "models = list(os.listdir(root_path))\n",
    "\n",
    "def plot_3(model_ind, cam_ind):\n",
    "    global cam_dict, orig_dict\n",
    "    model = models[model_ind]\n",
    "    print(f'Using {model}')\n",
    "    cam_dict, orig_dict = get_dict(model)\n",
    "    plot_2(cam_ind)\n",
    "\n",
    "interact(plot_3, model_ind=(0,len(models)-1), cam_ind=(0,len(good_inds)-1));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0acccb69-655a-4eff-8a22-c3ff8d759ff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cam_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mba_full_kmeans_closest_batch_cam_dict.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 4\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mcam_dict\u001b[49m, file)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mba_full_kmeans_closest_batch_orig_dict.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      7\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(orig_dict, file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cam_dict' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('ba_full_kmeans_closest_batch_cam_dict.pkl','wb') as file:\n",
    "    pickle.dump(cam_dict, file)\n",
    "    \n",
    "with open('ba_full_kmeans_closest_batch_orig_dict.pkl','wb') as file:\n",
    "    pickle.dump(orig_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366d97a-7daa-4098-a16f-bf19ab4b48b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
